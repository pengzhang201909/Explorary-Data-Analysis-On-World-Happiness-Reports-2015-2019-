---
title: "Explorary Data Analysis On World Happiness Reports(2015-2019)"
subtitle: "By Michael Chen, Alex Zhangpeng, Su Hongyang"
output: 
  html_document:
    df_print: paged
  github_document:
    default
  pdf_document: default
---

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```


```{r setup, include = FALSE}
library("tidyverse")
library("ggplot2")
library("stringr")
library(splines)
library(modelr)
library(forcats)
```


## Introduction

Everyone is looking for happiness. Then what factors influence man's feeling about happiness? Great income, healthy body, perfect family, enough freedom, generous neighbourhood and community, incorruptible governance,... It looks every individual factor does not define happiness directly but to some extent they play their roles in the process of how to feel happiness.

In this report we will analyze three characteristics of happiness across the world. First what was the trend of world happiness ranking recently. In other words, the world felt more happiness, or in reverse? Then, are countries more happier if they are more democratic? At last we will focus on some countries which have experienced huge happiness ranking changes, and try to find the reasons.

Certainly in this report we will use the UN World Happiness Reports from 2015 to 2019, and explorary data analysis tools in R.

Thank the United Nations Sustainable Development Solutions Network for providing World Happiness Report annually. Let's have this opportunity of Quantitative Analysis on World Happiness.

We were excited to find the UN World Happiness Reports have an index called as national happiness score  as well as six correlative life factors, which comprise a system of indicators to rank happiness across the world. The rankings of national happiness are based on a Cantril ladder survey. Nationally representative samples of respondents are asked to think of a ladder, with the best possible life for them being a 10, and the worst possible life being a 0. They are then asked to rate their own current lives on that 0 to 10 scale.

Q1, What was the trend of world happiness scores from 2015 to 2019? In general, people felt more happiness from 2015 to 2019?

Q2, Are countries more happier if they have more democratic freedoms?

Q3, from 2015 to 2019, which countries experienced huge happiness score change , both positive and negtive?

## Data Cleaning

### 3E Rules

When facing the five World Happiness Report datasets, I remembered the three interrelated rules which make a dataset tidy: 1. each variable must have its own column; 2. each observation must have its own row; 3. each value must have its own cell. These rules(I call it 3E Rules) were just what I followed when cleaning datasets in this project.

### Decide tidy dataset columns

Firstly I found there were 9 common variables in five datasets: rank, country, score, gdp per capita, social support, life expectancy, freedom, generosity, trust. First three of them  delivered informations about countries' names and their happiness ranking, the other were six key explanatory factors. Nevermind they had differnet names in different reports sometimes, I could easily find they were pointing to the same variables. For example, in 2015 report dataset there was a variable "Trust (Government Corruption)",then in 2018 and 2019 report datasets a variable "Perceptions of corruption" has taken the place. Because these variables had necessary informations to answer our questions I'd like to use the nine variables to create new tidy data frame.

However in 2015,2016 and 2017 reports datasets variable "family" came out instead of "social support". I seached the official website for this variable( https://worldhappiness.report/ ). There was only social support in the documentations throughout five years reports. So I treated "family" as input error and replaced it with "social support".

To analyze the changing trend of happiness among countries in the five years, I added time dimension with mutating column "year" .

When we have year and score columns, it's easy to caculate the ranking sequence for each country per year. Then I dropped the rank column off. Now nine columns again!

### Missing values

When reviewing the five original datasets in .csv type, I did NOT see any N/A character at all. After importing datasets, I met a problem when joining datasets. A warning message came out like this :
"Error: Column `trust` can't be converted from numeric to factor." I had to check "trust" column in every dataset, only 2018.csv had "trust" column(origin was "Perceptions.of.corruption") treated as factor. Keeping forward, I carefully reviewed any element of this column until meeting a N/A. This observation has country name as United Arab Emirates with happiness rank 20 in 2018. From the documentations, I learned one regular technical remedy action was to borrow the value of last year.  

I found some 0's presenting the values of a couple of key explanatory factors. They might be missing or not. According to the documentations, 0 represented the worst possible life in the Cantril ladder survey. It was an option and had possibility. Because I did not know how to do with it , so I kept those 0's. Luckily I did not find any happiness score with the value of 0!!!Just a joke.



### Dropped those countries which did not existed in all five years' datasets

For keeping our analysis in a continous time dimension, I took out of those observations whose countries' names did not have five years' records. However there were a couple of execptions. "Hong Kong" and "Taiwan" existed in 2015, 2016,2018 and 2019 reports except 2017, because the name of "Hong Kong S.A.R., China" and "Taiwan Province of China" have taken them in this year report. I restored the names of "Hong Kong" and "Taiwan" to 2017 dataset.   

```{r}
w_15 <- read.csv("2015.csv",stringsAsFactors = FALSE)
w_16 <- read.csv("2016.csv",stringsAsFactors = FALSE)
w_17 <- read.csv("2017.csv",stringsAsFactors = FALSE)
w_18 <- read.csv("2018revised.csv",stringsAsFactors = FALSE)
w_19 <- read.csv("2019.csv",stringsAsFactors = FALSE)
```


```{r}
w_15$year <- 2015
#glimpse(w_15)
```

```{r}
w_15 <- w_15 %>% select(-2,-3,-5,-12) %>% rename( 
"country" = "Country", "score" = "Happiness.Score", "gdp" = "Economy..GDP.per.Capita.", "socsupport" = "Family", "lexp" = "Health..Life.Expectancy.", "freedom" = "Freedom", "generosity" = "Generosity", "trust" = "Trust..Government.Corruption.")
#glimpse(w_15)
```


```{r}
w_16$year <- 2016
#glimpse(w_16)
```

```{r}
w_16 <- w_16 %>% select(-2,-3,-5,-6,-13) %>% rename("country" = "Country", "score" = "Happiness.Score", "gdp" = "Economy..GDP.per.Capita.", "socsupport" = "Family", "lexp" = "Health..Life.Expectancy.", "freedom" = "Freedom", "generosity" = "Generosity", "trust" = "Trust..Government.Corruption.")
#glimpse(w_16)
```

```{r}
w_17$year <- 2017
#glimpse(w_17)
```

```{r}
w_17 <- w_17 %>% 
  select(-2,-4,-5,-12) %>% 
  rename("country" = "Country", "score" = "Happiness.Score", "gdp" = "Economy..GDP.per.Capita.", "socsupport" = "Family", "lexp" = "Health..Life.Expectancy.", "freedom" = "Freedom", "generosity" = "Generosity", "trust" = "Trust..Government.Corruption.")
w_17$country[71] = "Hong Kong"
w_17$country[33] = "Taiwan"
#glimpse(w_17)
```

```{r}
w_18$year <- 2018
#glimpse(w_18)
```

```{r}
w_18 <- w_18 %>% select(-1) %>% rename("country" = "Country.or.region", "score" = "Score", "gdp" = "GDP.per.capita", "socsupport" = "Social.support", "lexp" = "Healthy.life.expectancy", "freedom" = "Freedom.to.make.life.choices", "generosity" = "Generosity", "trust" = "Perceptions.of.corruption")
w_18$country[141] = "Trinidad and Tobago"
#glimpse(w_18)
```

```{r}
w_19$year <- 2019
#glimpse(w_19)
```

```{r}
w_19 <- w_19 %>% select(-1) %>% rename("country" = "Country.or.region", "score" = "Score", "gdp" = "GDP.per.capita", "socsupport" = "Social.support", "lexp" = "Healthy.life.expectancy", "freedom" = "Freedom.to.make.life.choices", "generosity" = "Generosity", "trust" = "Perceptions.of.corruption")
w_19$country[141] = "Trinidad and Tobago"
#glimpse(w_19)
```


```{r}
w <- bind_rows(w_15,w_16,w_17,w_18,w_19)
```

```{r}
#Drop the countries that were not included in all 5 years. 2015+2016+2017+2018+2019 = 10085
w2 <- w %>% group_by(country) %>% mutate(count = sum(year)) %>% dplyr::filter(count == 10085)
w2 <- w2 %>% select(-10) %>%
  mutate(gdp = round(gdp,3),
         socsupport = round(socsupport,3),
         lexp=round(lexp,3),
         freedom=round(freedom,3),
         trust=round(trust,3),
         generosity=round(generosity,3))
#glimpse(w2)
```


### Question 1: What was the trend of world happiness scores from 2015 to 2019?

I combined all of the data for 5 years, and added Region for the last three years.
```{r message=FALSE}
aaa <- read_csv("2015.csv")
Country_Region <- aaa %>%
  select(Country, Region)
da15 <- read_csv("2015.csv")  
rank2015 <- da15 %>%
  select(Country,Region,`Happiness Rank`,`Happiness Score`) %>%
  rename(Rank=`Happiness Rank`) %>%
  rename(Score=`Happiness Score`) %>%
  mutate(year="2015")
da16 <- read_csv("2016.csv")
rank2016 <- da16 %>%
  select(Country,Region,`Happiness Rank`,`Happiness Score`) %>%
  rename(Rank=`Happiness Rank`) %>%
  rename(Score=`Happiness Score`) %>%
  mutate(year="2016")
da17 <- read_csv("2017.csv")
rank2017 <- da17 %>%
  left_join(Country_Region,by = "Country")%>%
  select(Country,Region,Happiness.Rank,Happiness.Score) %>%
  rename(Rank=Happiness.Rank) %>%
  rename(Score=Happiness.Score) %>%
  mutate(year="2017")
da18 <- read_csv("2018.csv")
rank2018 <- da18 %>%
  rename(Country=`Country or region`) %>%
  rename(Rank=`Overall rank`) %>%
  left_join(Country_Region,by = "Country")%>%
  select(Country,Region,Rank, Score) %>%
  mutate(year="2018")
da19 <- read_csv("2019.csv")
rank2019 <- da19 %>%
  rename(Country=`Country or region`) %>%
  rename(Rank=`Overall rank`) %>%
  left_join(Country_Region,by = "Country")%>%
  select(Country,Region,Rank, Score) %>%
  mutate(year="2019")
total<- tibble(
  Country=c(rank2015$Country ,rank2016$Country ,rank2017$Country  ,rank2018$Country ,rank2019$Country),
  Region=c(rank2015$Region ,rank2016$Region ,rank2017$Region  ,rank2018$Region ,rank2019$Region),
  Rank=c(rank2015$Rank ,rank2016$Rank ,rank2017$Rank ,rank2018$Rank ,rank2019$Rank),
  Score=c(rank2015$Score ,rank2016$Score ,rank2017$Score ,rank2018$Score ,rank2019$Score),
  year=c(rank2015$year ,rank2016$year ,rank2017$year ,rank2018$year ,rank2019$year)
  ) %>%
  arrange(Country,Rank)
totl <- na.omit(total)  
```


The geom_line graph of happiness score.
```{r}
totl %>% 
  ggplot(aes(year, Score, group = Country)) +
    geom_line(alpha = 1/3) + 
    labs(caption="Figure 1.1")
```

Get the data of predictions and residuals.
```{r}
by_country <- totl%>% 
  group_by(Country) %>% 
  nest()
country_model <- function(df) {
  lm(Score ~ year, data = totl)
}
by_country <- by_country %>% 
  mutate(model = map(data, country_model))
by_country <- by_country %>% 
  mutate(
    pred = map2(data, model, add_predictions)
  )
preds <- unnest(by_country, pred)
by_country <- by_country %>% 
  mutate(
    resids = map2(data, model, add_residuals)
  )
resids <- unnest(by_country, resids)
resids
```

Table 1.2

The boxplot graph of happiness score
```{r}
ggplot(resids, aes(year, Score)) +
 geom_boxplot() + 
  labs(caption="Figure 1.3")
```

The graph of residuals.
```{r}
ggplot(resids, aes(year, resid)) +
 geom_boxplot() + 
  labs(caption="Figure 1.4")
```
The graph of predictions.
```{r}
ggplot(preds, aes(year, pred)) +
 geom_point() + 
  labs(caption = "Figure 1.5")
```

Then I separate the countries into different Regions to check each Continent's happiness score Continent.
```{r}
ggplot(resids, aes(year, Score)) +
 geom_boxplot() +
 facet_wrap(~ Region, nrow = 2) + 
 theme(axis.text.x=element_text(angle=30, hjust=1)) + 
  labs(caption = "Figure 1.6")
```

The geom_line of predictions 
```{r message=FALSE}
preds %>% 
  ggplot(aes(year, pred)) +
    geom_line(aes(group = Country), alpha = 1/3) + 
    geom_point() + 
  labs(caption="Figure 1.7")
```


### Question 2: How does a country's amount of democratic freedoms affect its happiness?

To measure a country's amount of democratic freedoms, we'll use the data from https://www.gapminder.org/data/documentation/democracy-index/, which assigns each country a democracy index. The more democratic freedoms a country has, the higher the democracy index.


```{r message=FALSE}
democracy <- read_csv("DemocracyIndex.csv")
democracy <- democracy %>%
  #only the year, country, and democracy index columns are needed
  select(2,3,4) %>%
  #we only care about 2015+
  dplyr::filter(time>=2015) %>%
  #rename the columns
  transmute(year=as.character(time),country=name,DemocracyIndex = `Democracy index (EIU)`)
glimpse(democracy)
```

Figure 2.1, The Democracy table has 3 variables, and DemocracyIndex is a scale from 0-100 that gets higher the more democratic freedoms a country has.

This dataset only provides data up to year 2018, so we'll exclude the year 2019 from our analysis.

```{r}
w3 <- w2 %>%
  #Get rid of year 2019 from our original dataset
  dplyr::filter(year != 2019) %>%
  mutate(year = as.character(year))
```

We must also rename the countries so that they'll have the same name in both datasets, and get rid of any countries that aren't in both datasets.

We'll do this by first gathering a list of countries that aren't included in both datasets.

```{r message=FALSE}
anti_join(w3,democracy) %>% select(country)
```

Table 2.2 Countries that are either not present in both datasets, or are named differently

Then we'll look through each of them using `democracy$country` and determine if the countries should be renamed or removed

```{r}
democracy$country[633:636] = "United States"
democracy$country[65:68] = "Bosnia and Herzegovina"
democracy$country[461:464] = "Palestinian Territories"
democracy$country[133:136] = "Congo (Brazzaville)"
w3 <- w3 %>% 
  dplyr::filter(country != "Kosovo") %>% 
  dplyr::filter(country != "Congo (Kinshasa)") %>% 
  dplyr::filter(country != "Georgia") %>% 
  dplyr::filter(country != "Ivory Coast")
```

Our 2 datasets are tidied and ready for merging.

```{r message=FALSE}
data <- left_join(w3,democracy)
glimpse(data)
```

Figure 2.3 A glimpse of what our final dataset looks like when the democracy index is added in.

Let's visualize the relationship between the democracy index and the happiness score to spot any patterns. 

```{r message=FALSE}
data %>%
  ggplot() + 
  geom_point(aes(DemocracyIndex,score,color=year),size=0.9,alpha=7/8) + 
  geom_smooth(aes(DemocracyIndex,score,color=year),se=FALSE) +
  facet_wrap(~year) + 
  labs(x="Democracy Index",y="Happiness Score", title="Democracy Index vs Happiness Score by Year",caption="Figure 2.4 Visualizing the trend between democracy index and happiness score.") + 
  theme_bw()
```

For each of the years, we can see a mediocre positive quadratic relationship between the democracy index and their happiness score. Although there's more variation near the lower end of the democracy index, there's a strong correlation near the higher end of the demoracy index.

We will build a quadratic model that best fits the dataset using mean-square residuals.

```{r}
#Our quadratic model takes 3 parameters: a+ bx + cx^2
quadratic_model <- function(a, data) {
  a[1] + data$DemocracyIndex * a[2] + a[3] * (data$DemocracyIndex^2)
}

#The best model will have the smallest mean square residuals
measure_distance <- function(model, data) {
  difference <- data$score - quadratic_model(model, data)
  sqrt(mean(difference ^ 2))
}

#Create a dataset for each year so we can analyze them individually
data2015 <- data %>%
  dplyr::filter(year==2015)
data2016 <- data %>%
  dplyr::filter(year==2016)
data2017 <- data %>%
  dplyr::filter(year==2017)
data2018 <- data %>%
  dplyr::filter(year==2018)

#Find the best parameters for our quadratic model for each year
best2015 <- optim(c(0, 0, 0), measure_distance, data = data2015)
best2016 <- optim(c(0, 0, 0), measure_distance, data = data2016)
best2017 <- optim(c(0, 0, 0), measure_distance, data = data2017)
best2018 <- optim(c(0, 0, 0), measure_distance, data = data2018)

#Create a quadratic function for each model so we can plot them on our graph
function2015 <- function(x){ best2015$par[1] + best2015$par[2]*x + best2015$par[3]*(x^2) }
function2016 <- function(x){ best2016$par[1] + best2016$par[2]*x + best2016$par[3]*(x^2) }
function2017 <- function(x){ best2017$par[1] + best2017$par[2]*x + best2017$par[3]*(x^2) }
function2018 <- function(x){ best2018$par[1] + best2018$par[2]*x + best2018$par[3]*(x^2) }
```


```{r}
ggplot(data2015) +
  geom_point(aes(DemocracyIndex,score),color="red") +
  #stat_function() plots a function
  stat_function(fun = function2015) + 
  theme_bw() + 
  labs(title="2015",x="Democracy Index",y="Happiness Score",caption="Figure 2.5 Qudratic Regression for 2015")

ggplot(data2016) +
  geom_point(aes(DemocracyIndex,score),color="green") +
  #stat_function() plots a function
  stat_function(fun = function2016) + 
  theme_bw() + 
  labs(title="2016",x="Democracy Index",y="Happiness Score",caption="Figure 2.6 Qudratic Regression for 2016")

ggplot(data2017) +
  geom_point(aes(DemocracyIndex,score),color="blue") +
  #stat_function() plots a function
  stat_function(fun = function2017) + 
  theme_bw() + 
  labs(title="2017",x="Democracy Index",y="Happiness Score",caption="Figure 2.7 Qudratic Regression for 2017")

ggplot(data2018) +
  geom_point(aes(DemocracyIndex,score),color="purple") +
  #stat_function() plots a function
  stat_function(fun = function2018) + 
  theme_bw() + 
  labs(title="2018",x="Democracy Index",y="Happiness Score",caption="Figure 2.8 Qudratic Regression for 2018")
```

The quadratic regression appears to fit greatly, but we must make sure that our residual plots don't exhibit any patterns, and the residuals should be normally distributed around 0. The formula for a residual is (actual - expected).

```{r message=FALSE}
data2015 <- data2015 %>%
  mutate(residual = round(score - function2015(DemocracyIndex),2))
data2016 <- data2016 %>%
  mutate(residual = round(score - function2016(DemocracyIndex),2))
data2017 <- data2017 %>%
  mutate(residual = round(score - function2017(DemocracyIndex),2))
data2018 <- data2018 %>%
  mutate(residual = round(score - function2018(DemocracyIndex),2))

#put all the residuals into our original dataset
data <-  data2015 %>%
  full_join(data2016) %>%
  full_join(data2017) %>%
  full_join(data2018)
```


Let's make sure our residuals are normally distributed around 0.

```{r}
ggplot(data) + 
  geom_freqpoly(aes(residual,color=year),binwidth=0.2) + 
  geom_vline(xintercept=0,color="magenta",alpha=3/4) +
  facet_wrap(~year) + 
  theme_bw() + 
  labs(x="Residuals",y="Frequency",title="Residual Distribution",caption="Figure 2.9 Distribution of Residuals")
```

Every year's residual distribution is approximately normal and centered around 0. Next we'll look for any patterns in our residual plot.

```{r}
ggplot(data) + 
  geom_hline(yintercept = 0,color="magenta",size=1.4) + 
  geom_point(aes(DemocracyIndex,residual,color=year)) + 
  facet_wrap(~year) + 
  theme_bw() + 
  labs(title="Residual Plots",x="Democracy Index",y="Residuals",caption="Figure 2.10 Residual Plots")
```

The residual plots show no pattern, so our model is a pretty good estimator.

We'll calculate a coefficient of determination: r-sqaured.

The formula for r-squared is sum( (predicted_y - mean(y))^2 ) / sum( (observed_y - mean(y))^2 )

```{r}
rSquared2015 <- sum( ( function2015(data2015$DemocracyIndex) - mean(data2015$score) )^2) / sum( (data2015$score - mean(data2015$score))^2 )
rSquared2016 <- sum( ( function2016(data2016$DemocracyIndex) - mean(data2016$score) )^2) / sum( (data2016$score - mean(data2016$score))^2 )
rSquared2017 <- sum( ( function2017(data2017$DemocracyIndex) - mean(data2017$score) )^2) / sum( (data2017$score - mean(data2017$score))^2 )
rSquared2018 <- sum( ( function2018(data2018$DemocracyIndex) - mean(data2018$score) )^2) / sum( (data2018$score - mean(data2018$score))^2 )

#First we'll add the predicted DemocracyIndex values using their respected models
#Since each year has a different model, we'll utilize nested if-else statements to use the correct model
data %>% 
  mutate(prediction = ifelse(year==2015,
                             function2015(DemocracyIndex),
                      ifelse(year==2016,
                             function2016(DemocracyIndex),
                      ifelse(year==2017,
                             function2017(DemocracyIndex),
                             function2018(DemocracyIndex)
                                             )
                      ))
         ) %>% 
#Then we'll calculate each year's coefficient or determiniation using the formula
  group_by(year) %>%
  summarize(rSquared = sum( (prediction - mean(score))^2) / sum( (score - mean(score))^2))
```

Table 2.11 Coefficient of determiniation for each model

Based on our coefficients of determiniation, about 45%-50% of the data can be explained by our models. This isn't very good, and there may be better models, but it's also not too bad, and it may still be useful when predicting a country's happiness score based on its democracy index.

We may test this out against a country that we didn't use for our model, such as Angola

```{r message=FALSE}
w %>% dplyr::filter(country=="Angola") %>% 
  mutate(year = as.character(year)) %>% 
  left_join(democracy) %>%
  select(country,year,DemocracyIndex,score) %>%
  mutate(predicted_score = ifelse(year==2015,
                             function2015(DemocracyIndex),
                      ifelse(year==2016,
                             function2016(DemocracyIndex),
                      ifelse(year==2017,
                             function2017(DemocracyIndex),
                             function2018(DemocracyIndex)
                                             )
                      ))
         )
```

Table 2.12 Predicted happiness score for Angola is pretty close, mostly off by 1. Our model predicted that it'll have a happiness score around 4.7, while the actual happiness score is around 3.9.

## Conclusion


## Contributions
Michael - Wrote question 2.
Su Hongyang - Wrote question 1.



